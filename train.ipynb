{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO LIST FROM GANHACKS\n",
    "# https://github.com/soumith/ganhacks\n",
    "# ✓ Normalize the inputs\n",
    "# ✓ A modified loss function\n",
    "# ✓ Use a spherical Z\n",
    "# ✓ BatchNorm\n",
    "# Aviod sparse gradients\n",
    "# ✓ Use soft and noisy labels\n",
    "# ✓ DCGAN\n",
    "# Use stability tricks from RL\n",
    "# ✓ Use SGD for discriminator ADAM for generator\n",
    "# ✓ Add noise to inputs\n",
    "# Batch Discrimination (for diversity)\n",
    "# ✓ Use dropouts in G in both train and test phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "from ImageFeatureFolder import ImageFeatureFolder\n",
    "\n",
    "nc = 3\n",
    "nz = 100\n",
    "lr     = 0.00017\n",
    "beta1  = 0.0   \n",
    "beta2  = 0.99     \n",
    "imageSize = 64\n",
    "batchSize = 64\n",
    "\n",
    "outf = \"./celeba_result/\"\n",
    "des_dir = \"./celeba_normal/\"\n",
    "landmark_file = './list_landmarks_align_celeba.txt'\n",
    "\n",
    "dataset = ImageFeatureFolder(root=des_dir, landmark_file=landmark_file, imageSize=imageSize)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size= batchSize,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from Models import Generator, Discriminator\n",
    "import net_sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator()\n",
    "netD = Discriminator()\n",
    "feature_net = net_sphere.sphere20a(feature=True)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "input = torch.FloatTensor(batchSize, 3, imageSize,imageSize)\n",
    "noise = torch.FloatTensor(batchSize, nz, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(batchSize, nz, 1, 1).normal_(0, 1)\n",
    "\n",
    "label_real = torch.FloatTensor(batchSize)\n",
    "label_real_smooth = torch.FloatTensor(batchSize)\n",
    "label_fake = torch.FloatTensor(batchSize)\n",
    "\n",
    "netD.cuda()\n",
    "netG.cuda()\n",
    "criterion.cuda()\n",
    "feature_net.cuda()\n",
    "feature_net.load_state_dict(torch.load('./models/sphere20a_20171020.pth'))\n",
    "feature_net.eval()\n",
    "input, noise = input.cuda(), noise.cuda()\n",
    "label_real, label_real_smooth, label_fake = label_real.cuda(), label_real_smooth.cuda(), label_fake.cuda()\n",
    "fixed_noise = fixed_noise.cuda()\n",
    "\n",
    "label_real.resize_(batchSize, 1).fill_(1)\n",
    "label_fake.resize_(batchSize, 1).fill_(0)\n",
    "label_real_smooth.resize_(batchSize, 1).fill_(0.9)\n",
    "label_real = Variable(label_real)\n",
    "label_fake = Variable(label_fake)\n",
    "label_real_smooth = Variable(label_real_smooth)\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "fixed_noise = Variable(fixed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netD.load_state_dict(torch.load(outf + 'netD_epoch_003.pth'))\n",
    "# netG.load_state_dict(torch.load(outf + 'netG_epoch_003.pth'))\n",
    "import numpy as np\n",
    "_d_ = 0.0\n",
    "def add_noise(x, d_fake):\n",
    "    global _d_\n",
    "    if d_fake is not None:\n",
    "        _d_ = _d_ * 0.9 + float(torch.mean(d_fake).data[0]) * 0.1\n",
    "        strength = 0.2 * max(0, _d_ - 0.5)**2\n",
    "        z = np.random.randn(*x.size()).astype(np.float32) * strength\n",
    "        z = Variable(torch.from_numpy(z)).cuda()\n",
    "        return x + z\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100][0/3165] Loss_D: 0.7651 Loss_G: 1.2701 D(x): 0.1561 D(G(z)): 0.1269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100][500/3165] Loss_D: 0.4454 Loss_G: 0.6369 D(x): 0.4681 D(G(z)): 0.4671\n",
      "[0/100][1000/3165] Loss_D: 0.4481 Loss_G: 0.3634 D(x): 0.3486 D(G(z)): 0.2678\n",
      "[0/100][1500/3165] Loss_D: 0.4525 Loss_G: 1.6847 D(x): 0.7345 D(G(z)): 0.5720\n",
      "[0/100][2000/3165] Loss_D: 0.3940 Loss_G: 1.4144 D(x): 0.6945 D(G(z)): 0.4372\n",
      "[0/100][2500/3165] Loss_D: 0.2334 Loss_G: 0.9225 D(x): 0.6341 D(G(z)): 0.3313\n",
      "[0/100][3000/3165] Loss_D: 0.2328 Loss_G: 1.6349 D(x): 0.8236 D(G(z)): 0.3878\n",
      "[1/100][0/3165] Loss_D: 0.1576 Loss_G: 0.9187 D(x): 0.6692 D(G(z)): 0.2204\n",
      "[1/100][500/3165] Loss_D: 0.1732 Loss_G: 1.4006 D(x): 0.8099 D(G(z)): 0.3604\n",
      "[1/100][1000/3165] Loss_D: 0.1826 Loss_G: 0.9280 D(x): 0.6132 D(G(z)): 0.2579\n",
      "[1/100][1500/3165] Loss_D: 0.1275 Loss_G: 1.4249 D(x): 0.7750 D(G(z)): 0.2325\n",
      "[1/100][2000/3165] Loss_D: 0.1598 Loss_G: 0.3571 D(x): 0.5881 D(G(z)): -0.1352\n",
      "[1/100][2500/3165] Loss_D: 0.2773 Loss_G: 1.9509 D(x): 0.7722 D(G(z)): 0.4591\n",
      "[1/100][3000/3165] Loss_D: 0.1852 Loss_G: 1.5033 D(x): 0.7575 D(G(z)): 0.3562\n",
      "[2/100][0/3165] Loss_D: 0.1028 Loss_G: 1.6120 D(x): 0.8834 D(G(z)): 0.2137\n",
      "[2/100][500/3165] Loss_D: 0.3151 Loss_G: 0.0866 D(x): 0.4124 D(G(z)): -0.1577\n",
      "[2/100][1000/3165] Loss_D: 0.1331 Loss_G: 0.4699 D(x): 0.6348 D(G(z)): -0.1102\n",
      "[2/100][1500/3165] Loss_D: 0.1944 Loss_G: 0.1617 D(x): 0.5658 D(G(z)): -0.1889\n",
      "[2/100][2000/3165] Loss_D: 0.1080 Loss_G: 2.0587 D(x): 0.8597 D(G(z)): 0.2714\n",
      "[2/100][2500/3165] Loss_D: 0.3357 Loss_G: 0.2393 D(x): 0.3652 D(G(z)): -0.0673\n",
      "[2/100][3000/3165] Loss_D: 0.0617 Loss_G: 0.9562 D(x): 0.7692 D(G(z)): 0.0962\n",
      "[3/100][0/3165] Loss_D: 0.1235 Loss_G: 0.8722 D(x): 0.6265 D(G(z)): 0.1531\n",
      "[3/100][500/3165] Loss_D: 0.0925 Loss_G: 1.3963 D(x): 0.7850 D(G(z)): 0.1799\n",
      "[3/100][1000/3165] Loss_D: 0.1454 Loss_G: 0.3093 D(x): 0.6197 D(G(z)): -0.1285\n",
      "[3/100][1500/3165] Loss_D: 0.1826 Loss_G: 2.2256 D(x): 1.0233 D(G(z)): 0.3703\n",
      "[3/100][2000/3165] Loss_D: 0.2394 Loss_G: 2.3399 D(x): 0.9837 D(G(z)): 0.4376\n",
      "[3/100][2500/3165] Loss_D: 0.1380 Loss_G: 1.3311 D(x): 0.7026 D(G(z)): 0.2480\n",
      "[3/100][3000/3165] Loss_D: 0.0951 Loss_G: 0.9830 D(x): 0.6804 D(G(z)): 0.1551\n",
      "[4/100][0/3165] Loss_D: 0.3748 Loss_G: 2.5701 D(x): 1.0548 D(G(z)): 0.5490\n",
      "[4/100][500/3165] Loss_D: 0.1884 Loss_G: 0.5842 D(x): 0.5325 D(G(z)): 0.0927\n",
      "[4/100][1000/3165] Loss_D: 0.0938 Loss_G: 0.5713 D(x): 0.6642 D(G(z)): -0.0726\n",
      "[4/100][1500/3165] Loss_D: 0.2541 Loss_G: 1.7306 D(x): 0.8442 D(G(z)): 0.4485\n",
      "[4/100][2000/3165] Loss_D: 0.1026 Loss_G: 0.4580 D(x): 0.6709 D(G(z)): -0.1325\n",
      "[4/100][2500/3165] Loss_D: 0.1029 Loss_G: 0.7377 D(x): 0.6558 D(G(z)): 0.0309\n",
      "[4/100][3000/3165] Loss_D: 0.1379 Loss_G: 0.4853 D(x): 0.5665 D(G(z)): -0.0335\n",
      "[5/100][0/3165] Loss_D: 0.0479 Loss_G: 0.7389 D(x): 0.7457 D(G(z)): -0.0246\n",
      "[5/100][500/3165] Loss_D: 0.5617 Loss_G: 0.0623 D(x): 0.1959 D(G(z)): -0.1936\n",
      "[5/100][1000/3165] Loss_D: 0.1105 Loss_G: 0.8694 D(x): 0.6553 D(G(z)): 0.1317\n",
      "[5/100][1500/3165] Loss_D: 0.2027 Loss_G: 0.7249 D(x): 0.5207 D(G(z)): 0.1617\n",
      "[5/100][2000/3165] Loss_D: 0.0848 Loss_G: 1.3684 D(x): 0.7571 D(G(z)): 0.1923\n",
      "[5/100][2500/3165] Loss_D: 0.1127 Loss_G: 1.9258 D(x): 0.9586 D(G(z)): 0.2894\n",
      "[5/100][3000/3165] Loss_D: 0.0689 Loss_G: 1.7184 D(x): 0.9849 D(G(z)): 0.1542\n",
      "[6/100][0/3165] Loss_D: 0.0741 Loss_G: 0.8447 D(x): 0.6912 D(G(z)): 0.0585\n",
      "[6/100][500/3165] Loss_D: 0.1304 Loss_G: 1.7936 D(x): 0.8212 D(G(z)): 0.2955\n",
      "[6/100][1000/3165] Loss_D: 0.0533 Loss_G: 1.4701 D(x): 0.9503 D(G(z)): 0.1234\n",
      "[6/100][1500/3165] Loss_D: 0.1474 Loss_G: 0.7763 D(x): 0.5858 D(G(z)): 0.1131\n",
      "[6/100][2000/3165] Loss_D: 0.0721 Loss_G: 1.3906 D(x): 0.7449 D(G(z)): 0.1341\n",
      "[6/100][2500/3165] Loss_D: 0.0914 Loss_G: 1.6012 D(x): 0.8987 D(G(z)): 0.2511\n",
      "[6/100][3000/3165] Loss_D: 0.1416 Loss_G: 1.6039 D(x): 0.7417 D(G(z)): 0.2791\n",
      "[7/100][0/3165] Loss_D: 0.2406 Loss_G: 2.3697 D(x): 1.0771 D(G(z)): 0.4167\n",
      "[7/100][500/3165] Loss_D: 0.0766 Loss_G: 0.9224 D(x): 0.7132 D(G(z)): 0.0787\n",
      "[7/100][1000/3165] Loss_D: 0.1834 Loss_G: 1.9366 D(x): 1.1084 D(G(z)): 0.3252\n",
      "[7/100][1500/3165] Loss_D: 0.1510 Loss_G: 0.9797 D(x): 0.5776 D(G(z)): 0.1399\n",
      "[7/100][2000/3165] Loss_D: 0.0451 Loss_G: 1.0835 D(x): 0.7958 D(G(z)): 0.1026\n",
      "[7/100][2500/3165] Loss_D: 0.1025 Loss_G: 1.8536 D(x): 0.9561 D(G(z)): 0.2750\n",
      "[7/100][3000/3165] Loss_D: 0.3731 Loss_G: 0.3196 D(x): 0.3119 D(G(z)): -0.0045\n",
      "[8/100][0/3165] Loss_D: 0.0290 Loss_G: 1.1806 D(x): 0.9212 D(G(z)): 0.0588\n",
      "[8/100][500/3165] Loss_D: 0.1466 Loss_G: 1.9282 D(x): 0.8955 D(G(z)): 0.3498\n",
      "[8/100][1000/3165] Loss_D: 0.1122 Loss_G: 0.7623 D(x): 0.6178 D(G(z)): 0.0744\n",
      "[8/100][1500/3165] Loss_D: 0.1698 Loss_G: 1.7940 D(x): 0.9775 D(G(z)): 0.3637\n",
      "[8/100][2000/3165] Loss_D: 0.0839 Loss_G: 1.1223 D(x): 0.7343 D(G(z)): 0.1612\n",
      "[8/100][2500/3165] Loss_D: 0.0643 Loss_G: 1.6427 D(x): 0.8901 D(G(z)): 0.1977\n",
      "[8/100][3000/3165] Loss_D: 0.1297 Loss_G: 2.0064 D(x): 0.8565 D(G(z)): 0.3097\n",
      "[9/100][0/3165] Loss_D: 0.2380 Loss_G: 0.1597 D(x): 0.4883 D(G(z)): -0.2012\n",
      "[9/100][500/3165] Loss_D: 0.1049 Loss_G: 0.4391 D(x): 0.6269 D(G(z)): -0.0915\n",
      "[9/100][1000/3165] Loss_D: 0.1641 Loss_G: 0.5979 D(x): 0.5466 D(G(z)): 0.1125\n",
      "[9/100][1500/3165] Loss_D: 0.0296 Loss_G: 1.1518 D(x): 0.9642 D(G(z)): 0.0123\n",
      "[9/100][2000/3165] Loss_D: 0.1701 Loss_G: 0.2352 D(x): 0.6174 D(G(z)): -0.2553\n",
      "[9/100][2500/3165] Loss_D: 0.1867 Loss_G: 1.9689 D(x): 0.7866 D(G(z)): 0.3805\n",
      "[9/100][3000/3165] Loss_D: 0.0706 Loss_G: 0.9423 D(x): 0.7190 D(G(z)): 0.1146\n",
      "[10/100][0/3165] Loss_D: 0.1248 Loss_G: 2.0492 D(x): 0.9539 D(G(z)): 0.3094\n",
      "[10/100][500/3165] Loss_D: 0.0525 Loss_G: 0.7115 D(x): 0.7307 D(G(z)): -0.0414\n",
      "[10/100][1000/3165] Loss_D: 0.0454 Loss_G: 0.7688 D(x): 0.7520 D(G(z)): -0.0149\n",
      "[10/100][1500/3165] Loss_D: 0.2236 Loss_G: 0.6098 D(x): 0.4830 D(G(z)): 0.1366\n",
      "[10/100][2000/3165] Loss_D: 0.1067 Loss_G: 2.1092 D(x): 0.8368 D(G(z)): 0.2763\n",
      "[10/100][2500/3165] Loss_D: 0.0839 Loss_G: 0.8436 D(x): 0.6836 D(G(z)): 0.0833\n",
      "[10/100][3000/3165] Loss_D: 0.0664 Loss_G: 1.6606 D(x): 0.9336 D(G(z)): 0.2224\n",
      "[11/100][0/3165] Loss_D: 0.0437 Loss_G: 0.8274 D(x): 0.7778 D(G(z)): 0.0153\n",
      "[11/100][500/3165] Loss_D: 0.0205 Loss_G: 0.9975 D(x): 0.9365 D(G(z)): -0.0260\n",
      "[11/100][1000/3165] Loss_D: 0.0660 Loss_G: 0.6009 D(x): 0.7089 D(G(z)): -0.0679\n",
      "[11/100][1500/3165] Loss_D: 0.0538 Loss_G: 1.0463 D(x): 0.7468 D(G(z)): 0.1164\n",
      "[11/100][2000/3165] Loss_D: 0.0861 Loss_G: 1.2489 D(x): 0.7305 D(G(z)): 0.1818\n",
      "[11/100][2500/3165] Loss_D: 0.0215 Loss_G: 1.1258 D(x): 0.9105 D(G(z)): 0.0337\n",
      "[11/100][3000/3165] Loss_D: 0.3144 Loss_G: 2.3706 D(x): 0.9224 D(G(z)): 0.5444\n",
      "[12/100][0/3165] Loss_D: 0.0755 Loss_G: 1.9064 D(x): 0.9442 D(G(z)): 0.2413\n",
      "[12/100][500/3165] Loss_D: 0.0788 Loss_G: 1.7510 D(x): 0.8909 D(G(z)): 0.2396\n",
      "[12/100][1000/3165] Loss_D: 0.0229 Loss_G: 1.2337 D(x): 0.8827 D(G(z)): 0.0963\n",
      "[12/100][1500/3165] Loss_D: 0.0631 Loss_G: 0.7058 D(x): 0.6886 D(G(z)): 0.0089\n",
      "[12/100][2000/3165] Loss_D: 0.0176 Loss_G: 0.9487 D(x): 0.8677 D(G(z)): -0.0024\n",
      "[12/100][2500/3165] Loss_D: 0.0411 Loss_G: 1.5378 D(x): 0.8836 D(G(z)): 0.1420\n",
      "[12/100][3000/3165] Loss_D: 0.1340 Loss_G: 0.4183 D(x): 0.5695 D(G(z)): -0.0672\n",
      "[13/100][0/3165] Loss_D: 0.0593 Loss_G: 1.1828 D(x): 0.7616 D(G(z)): 0.1486\n",
      "[13/100][500/3165] Loss_D: 0.0508 Loss_G: 1.1480 D(x): 0.7617 D(G(z)): 0.1374\n",
      "[13/100][1000/3165] Loss_D: 0.1419 Loss_G: 0.2983 D(x): 0.6704 D(G(z)): -0.2646\n",
      "[13/100][1500/3165] Loss_D: 0.0976 Loss_G: 1.2706 D(x): 0.8091 D(G(z)): 0.2631\n",
      "[13/100][2000/3165] Loss_D: 0.0522 Loss_G: 1.0851 D(x): 0.7492 D(G(z)): 0.1199\n",
      "[13/100][2500/3165] Loss_D: 0.1358 Loss_G: 2.0946 D(x): 0.9129 D(G(z)): 0.3494\n",
      "[13/100][3000/3165] Loss_D: 0.0640 Loss_G: 0.5295 D(x): 0.8385 D(G(z)): -0.2110\n",
      "[14/100][0/3165] Loss_D: 0.0167 Loss_G: 0.9025 D(x): 0.8436 D(G(z)): -0.0271\n",
      "[14/100][500/3165] Loss_D: 0.0332 Loss_G: 1.3335 D(x): 0.8626 D(G(z)): 0.1429\n",
      "[14/100][1000/3165] Loss_D: 0.0213 Loss_G: 1.1390 D(x): 0.9662 D(G(z)): 0.0825\n",
      "[14/100][1500/3165] Loss_D: 0.0159 Loss_G: 0.9011 D(x): 0.8367 D(G(z)): -0.0099\n",
      "[14/100][2000/3165] Loss_D: 0.0444 Loss_G: 0.7108 D(x): 0.7223 D(G(z)): 0.0129\n",
      "[14/100][2500/3165] Loss_D: 0.0326 Loss_G: 0.7382 D(x): 0.7929 D(G(z)): -0.1044\n",
      "[14/100][3000/3165] Loss_D: 0.0153 Loss_G: 1.0805 D(x): 0.9674 D(G(z)): 0.0099\n",
      "[15/100][0/3165] Loss_D: 0.0164 Loss_G: 0.8687 D(x): 0.8257 D(G(z)): -0.0301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/100][500/3165] Loss_D: 0.0308 Loss_G: 0.7741 D(x): 0.8793 D(G(z)): -0.1491\n",
      "[15/100][1000/3165] Loss_D: 0.0809 Loss_G: 0.5403 D(x): 0.7407 D(G(z)): -0.2121\n",
      "[15/100][1500/3165] Loss_D: 0.0259 Loss_G: 0.9680 D(x): 0.8036 D(G(z)): 0.0584\n",
      "[15/100][2000/3165] Loss_D: 0.0252 Loss_G: 0.7422 D(x): 0.7693 D(G(z)): -0.0374\n",
      "[15/100][2500/3165] Loss_D: 0.0169 Loss_G: 0.9965 D(x): 0.8333 D(G(z)): 0.0418\n",
      "[15/100][3000/3165] Loss_D: 0.0186 Loss_G: 0.8734 D(x): 0.7977 D(G(z)): -0.0243\n",
      "[16/100][0/3165] Loss_D: 0.0160 Loss_G: 1.1331 D(x): 0.9638 D(G(z)): 0.0455\n",
      "[16/100][500/3165] Loss_D: 0.1159 Loss_G: 1.6873 D(x): 0.7911 D(G(z)): 0.2982\n",
      "[16/100][1000/3165] Loss_D: 0.1681 Loss_G: 0.5625 D(x): 0.5199 D(G(z)): -0.1125\n",
      "[16/100][1500/3165] Loss_D: 0.0751 Loss_G: 1.6319 D(x): 1.0005 D(G(z)): 0.2308\n",
      "[16/100][2000/3165] Loss_D: 0.2516 Loss_G: 0.4993 D(x): 0.4733 D(G(z)): -0.2421\n",
      "[16/100][2500/3165] Loss_D: 0.0560 Loss_G: 1.3756 D(x): 0.8859 D(G(z)): 0.2147\n",
      "[16/100][3000/3165] Loss_D: 0.0159 Loss_G: 1.0182 D(x): 0.9558 D(G(z)): -0.0307\n",
      "[17/100][0/3165] Loss_D: 0.0128 Loss_G: 1.0587 D(x): 0.8486 D(G(z)): 0.0433\n",
      "[17/100][500/3165] Loss_D: 0.0259 Loss_G: 0.7828 D(x): 0.8231 D(G(z)): -0.0863\n",
      "[17/100][1000/3165] Loss_D: 0.0690 Loss_G: 0.5022 D(x): 0.6574 D(G(z)): -0.0115\n",
      "[17/100][1500/3165] Loss_D: 0.1174 Loss_G: 2.0505 D(x): 0.8596 D(G(z)): 0.3274\n",
      "[17/100][2000/3165] Loss_D: 0.0282 Loss_G: 0.7264 D(x): 0.8063 D(G(z)): -0.0877\n",
      "[17/100][2500/3165] Loss_D: 0.0369 Loss_G: 0.9686 D(x): 0.7579 D(G(z)): 0.0800\n",
      "[17/100][3000/3165] Loss_D: 0.0135 Loss_G: 1.0539 D(x): 0.9240 D(G(z)): 0.0678\n",
      "[18/100][0/3165] Loss_D: 0.0065 Loss_G: 0.9753 D(x): 0.8737 D(G(z)): -0.0045\n",
      "[18/100][500/3165] Loss_D: 0.0878 Loss_G: 0.6331 D(x): 0.6629 D(G(z)): -0.1433\n",
      "[18/100][1000/3165] Loss_D: 0.0197 Loss_G: 1.0220 D(x): 0.8058 D(G(z)): 0.0446\n",
      "[18/100][1500/3165] Loss_D: 0.0305 Loss_G: 0.8079 D(x): 0.9087 D(G(z)): -0.1435\n",
      "[18/100][2000/3165] Loss_D: 0.0108 Loss_G: 1.1954 D(x): 0.9376 D(G(z)): 0.0540\n",
      "[18/100][2500/3165] Loss_D: 0.0241 Loss_G: 1.1544 D(x): 0.8457 D(G(z)): 0.1077\n",
      "[18/100][3000/3165] Loss_D: 0.0127 Loss_G: 0.8720 D(x): 0.8509 D(G(z)): -0.0251\n",
      "[19/100][0/3165] Loss_D: 0.0429 Loss_G: 1.1449 D(x): 1.0691 D(G(z)): 0.0737\n",
      "[19/100][500/3165] Loss_D: 0.0363 Loss_G: 0.9236 D(x): 0.7837 D(G(z)): 0.0818\n",
      "[19/100][1000/3165] Loss_D: 0.0544 Loss_G: 1.5288 D(x): 0.9063 D(G(z)): 0.2126\n",
      "[19/100][1500/3165] Loss_D: 0.0102 Loss_G: 1.0364 D(x): 0.9026 D(G(z)): 0.0543\n",
      "[19/100][2000/3165] Loss_D: 0.1109 Loss_G: 1.3637 D(x): 0.8266 D(G(z)): 0.3012\n",
      "[19/100][2500/3165] Loss_D: 0.0181 Loss_G: 1.1239 D(x): 0.9382 D(G(z)): 0.0933\n",
      "[19/100][3000/3165] Loss_D: 0.0078 Loss_G: 1.1527 D(x): 0.9221 D(G(z)): 0.0590\n",
      "[20/100][0/3165] Loss_D: 0.0124 Loss_G: 1.0905 D(x): 0.9374 D(G(z)): 0.0250\n",
      "[20/100][500/3165] Loss_D: 0.0123 Loss_G: 1.0966 D(x): 0.8803 D(G(z)): 0.0633\n",
      "[20/100][1000/3165] Loss_D: 0.0512 Loss_G: 1.5298 D(x): 0.8969 D(G(z)): 0.1939\n",
      "[20/100][1500/3165] Loss_D: 0.9642 Loss_G: 0.1348 D(x): -0.0035 D(G(z)): -0.3648\n",
      "[20/100][2000/3165] Loss_D: 0.0348 Loss_G: 0.7166 D(x): 0.7828 D(G(z)): -0.0693\n",
      "[20/100][2500/3165] Loss_D: 0.0100 Loss_G: 1.0215 D(x): 0.8867 D(G(z)): 0.0216\n",
      "[20/100][3000/3165] Loss_D: 0.0489 Loss_G: 0.7990 D(x): 0.7096 D(G(z)): -0.0668\n",
      "[21/100][0/3165] Loss_D: 0.0101 Loss_G: 1.0388 D(x): 0.9031 D(G(z)): 0.0169\n",
      "[21/100][500/3165] Loss_D: 0.0139 Loss_G: 1.0663 D(x): 0.9096 D(G(z)): 0.0339\n",
      "[21/100][1000/3165] Loss_D: 0.0258 Loss_G: 0.7988 D(x): 0.7801 D(G(z)): -0.0686\n",
      "[21/100][1500/3165] Loss_D: 0.0680 Loss_G: 1.4732 D(x): 0.8963 D(G(z)): 0.2366\n",
      "[21/100][2000/3165] Loss_D: 0.1826 Loss_G: 2.0354 D(x): 1.0031 D(G(z)): 0.3974\n",
      "[21/100][2500/3165] Loss_D: 0.0205 Loss_G: 1.0504 D(x): 0.9332 D(G(z)): 0.1055\n",
      "[21/100][3000/3165] Loss_D: 0.0265 Loss_G: 1.1066 D(x): 0.9120 D(G(z)): 0.1256\n",
      "[22/100][0/3165] Loss_D: 0.0253 Loss_G: 1.1028 D(x): 0.8029 D(G(z)): 0.0845\n",
      "[22/100][500/3165] Loss_D: 0.0718 Loss_G: 1.9338 D(x): 0.9983 D(G(z)): 0.2201\n",
      "[22/100][1000/3165] Loss_D: 0.0173 Loss_G: 0.9264 D(x): 0.8134 D(G(z)): 0.0019\n",
      "[22/100][1500/3165] Loss_D: 0.1102 Loss_G: 1.8809 D(x): 0.8764 D(G(z)): 0.3191\n",
      "[22/100][2000/3165] Loss_D: 0.0114 Loss_G: 0.9512 D(x): 0.8359 D(G(z)): -0.0301\n",
      "[22/100][2500/3165] Loss_D: 0.0189 Loss_G: 1.1207 D(x): 0.9387 D(G(z)): 0.0957\n",
      "[22/100][3000/3165] Loss_D: 0.0681 Loss_G: 0.8953 D(x): 0.6950 D(G(z)): 0.1212\n",
      "[23/100][0/3165] Loss_D: 0.0189 Loss_G: 0.9447 D(x): 0.9962 D(G(z)): -0.0363\n",
      "[23/100][500/3165] Loss_D: 0.0342 Loss_G: 0.6987 D(x): 0.7853 D(G(z)): -0.1053\n",
      "[23/100][1000/3165] Loss_D: 0.0288 Loss_G: 0.7594 D(x): 0.8031 D(G(z)): -0.0927\n",
      "[23/100][1500/3165] Loss_D: 0.0254 Loss_G: 1.1714 D(x): 0.9009 D(G(z)): 0.1317\n",
      "[23/100][2000/3165] Loss_D: 0.0068 Loss_G: 0.9943 D(x): 0.8559 D(G(z)): 0.0110\n",
      "[23/100][2500/3165] Loss_D: 0.0107 Loss_G: 1.0003 D(x): 0.8695 D(G(z)): 0.0511\n",
      "[23/100][3000/3165] Loss_D: 0.0061 Loss_G: 1.0449 D(x): 0.9141 D(G(z)): 0.0203\n",
      "[24/100][0/3165] Loss_D: 0.0694 Loss_G: 1.6724 D(x): 1.0191 D(G(z)): 0.2162\n",
      "[24/100][500/3165] Loss_D: 0.0522 Loss_G: 0.8018 D(x): 0.7109 D(G(z)): -0.0216\n",
      "[24/100][1000/3165] Loss_D: 0.0511 Loss_G: 1.3881 D(x): 1.0504 D(G(z)): 0.1435\n",
      "[24/100][1500/3165] Loss_D: 0.0184 Loss_G: 1.0932 D(x): 0.8516 D(G(z)): 0.0892\n",
      "[24/100][2000/3165] Loss_D: 0.0054 Loss_G: 0.9852 D(x): 0.8907 D(G(z)): -0.0228\n",
      "[24/100][2500/3165] Loss_D: 0.0058 Loss_G: 1.0112 D(x): 0.9126 D(G(z)): 0.0222\n",
      "[24/100][3000/3165] Loss_D: 0.0169 Loss_G: 1.2268 D(x): 0.9675 D(G(z)): 0.0720\n",
      "[25/100][0/3165] Loss_D: 0.0113 Loss_G: 1.0430 D(x): 0.9752 D(G(z)): -0.0169\n",
      "[25/100][500/3165] Loss_D: 0.0176 Loss_G: 0.8725 D(x): 0.8066 D(G(z)): -0.0028\n",
      "[25/100][1000/3165] Loss_D: 0.0209 Loss_G: 0.9541 D(x): 0.7860 D(G(z)): -0.0006\n",
      "[25/100][1500/3165] Loss_D: 0.0151 Loss_G: 1.0574 D(x): 0.9729 D(G(z)): 0.0584\n",
      "[25/100][2000/3165] Loss_D: 0.0270 Loss_G: 0.9490 D(x): 0.7718 D(G(z)): 0.0448\n",
      "[25/100][2500/3165] Loss_D: 0.0080 Loss_G: 0.9829 D(x): 0.9309 D(G(z)): -0.0361\n",
      "[25/100][3000/3165] Loss_D: 0.0372 Loss_G: 1.2119 D(x): 0.9038 D(G(z)): 0.1769\n",
      "[26/100][0/3165] Loss_D: 0.5740 Loss_G: 0.3171 D(x): 0.1476 D(G(z)): -0.0423\n",
      "[26/100][500/3165] Loss_D: 0.0065 Loss_G: 0.9741 D(x): 0.8550 D(G(z)): -0.0203\n",
      "[26/100][1000/3165] Loss_D: 0.0671 Loss_G: 1.5129 D(x): 0.9026 D(G(z)): 0.2479\n",
      "[26/100][1500/3165] Loss_D: 0.0365 Loss_G: 1.2546 D(x): 0.9963 D(G(z)): 0.1296\n",
      "[26/100][2000/3165] Loss_D: 0.0265 Loss_G: 0.7045 D(x): 0.8939 D(G(z)): -0.1496\n",
      "[26/100][2500/3165] Loss_D: 0.0109 Loss_G: 0.8693 D(x): 0.8548 D(G(z)): -0.0550\n",
      "[26/100][3000/3165] Loss_D: 0.0171 Loss_G: 0.8570 D(x): 0.8315 D(G(z)): -0.0593\n",
      "[27/100][0/3165] Loss_D: 0.0230 Loss_G: 0.9329 D(x): 0.8012 D(G(z)): 0.0746\n",
      "[27/100][500/3165] Loss_D: 0.0392 Loss_G: 1.5291 D(x): 0.9680 D(G(z)): 0.1656\n",
      "[27/100][1000/3165] Loss_D: 0.0054 Loss_G: 0.9882 D(x): 0.8778 D(G(z)): 0.0076\n",
      "[27/100][1500/3165] Loss_D: 0.0618 Loss_G: 1.6371 D(x): 0.9231 D(G(z)): 0.2344\n",
      "[27/100][2000/3165] Loss_D: 0.0191 Loss_G: 0.7389 D(x): 0.8461 D(G(z)): -0.1068\n",
      "[27/100][2500/3165] Loss_D: 0.0221 Loss_G: 0.9337 D(x): 0.7686 D(G(z)): 0.0071\n",
      "[27/100][3000/3165] Loss_D: 0.0268 Loss_G: 0.9427 D(x): 0.7486 D(G(z)): -0.0259\n",
      "[28/100][0/3165] Loss_D: 0.0036 Loss_G: 1.0524 D(x): 0.9077 D(G(z)): 0.0335\n",
      "[28/100][500/3165] Loss_D: 0.0105 Loss_G: 1.0302 D(x): 0.9558 D(G(z)): 0.0328\n",
      "[28/100][1000/3165] Loss_D: 0.0134 Loss_G: 1.2483 D(x): 0.9317 D(G(z)): 0.0935\n",
      "[28/100][1500/3165] Loss_D: 0.1003 Loss_G: 0.6535 D(x): 0.6264 D(G(z)): 0.1160\n",
      "[28/100][2000/3165] Loss_D: 0.0036 Loss_G: 1.0095 D(x): 0.9012 D(G(z)): 0.0082\n",
      "[28/100][2500/3165] Loss_D: 0.0043 Loss_G: 1.0252 D(x): 0.9269 D(G(z)): 0.0175\n",
      "[28/100][3000/3165] Loss_D: 0.0067 Loss_G: 1.0229 D(x): 0.8733 D(G(z)): 0.0444\n",
      "[29/100][0/3165] Loss_D: 0.0068 Loss_G: 1.0370 D(x): 0.8770 D(G(z)): 0.0497\n",
      "[29/100][500/3165] Loss_D: 0.0083 Loss_G: 0.8455 D(x): 0.9213 D(G(z)): -0.0338\n",
      "[29/100][1000/3165] Loss_D: 0.0333 Loss_G: 0.8710 D(x): 0.7541 D(G(z)): 0.0404\n",
      "[29/100][1500/3165] Loss_D: 0.1317 Loss_G: 0.2918 D(x): 0.5636 D(G(z)): -0.1007\n",
      "[29/100][2000/3165] Loss_D: 0.0333 Loss_G: 0.9215 D(x): 0.7593 D(G(z)): -0.0454\n",
      "[29/100][2500/3165] Loss_D: 0.0097 Loss_G: 1.0421 D(x): 0.9605 D(G(z)): 0.0211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/100][3000/3165] Loss_D: 0.0047 Loss_G: 1.0188 D(x): 0.9347 D(G(z)): -0.0003\n",
      "[30/100][0/3165] Loss_D: 0.0176 Loss_G: 0.8912 D(x): 0.8493 D(G(z)): -0.0985\n",
      "[30/100][500/3165] Loss_D: 0.0146 Loss_G: 0.9182 D(x): 0.9669 D(G(z)): -0.0683\n",
      "[30/100][1000/3165] Loss_D: 0.1679 Loss_G: 1.8707 D(x): 0.9852 D(G(z)): 0.3909\n",
      "[30/100][1500/3165] Loss_D: 0.0209 Loss_G: 0.9580 D(x): 0.7918 D(G(z)): 0.0559\n",
      "[30/100][2000/3165] Loss_D: 0.0058 Loss_G: 1.0201 D(x): 0.9482 D(G(z)): 0.0124\n",
      "[30/100][2500/3165] Loss_D: 0.0093 Loss_G: 1.1446 D(x): 0.9706 D(G(z)): 0.0395\n",
      "[30/100][3000/3165] Loss_D: 0.1453 Loss_G: 1.5438 D(x): 0.9339 D(G(z)): 0.3702\n",
      "[31/100][0/3165] Loss_D: 0.0409 Loss_G: 1.4273 D(x): 0.9104 D(G(z)): 0.1760\n",
      "[31/100][500/3165] Loss_D: 0.0666 Loss_G: 1.7334 D(x): 0.9794 D(G(z)): 0.2261\n",
      "[31/100][1000/3165] Loss_D: 0.0165 Loss_G: 1.1877 D(x): 0.8978 D(G(z)): 0.1111\n",
      "[31/100][1500/3165] Loss_D: 0.0245 Loss_G: 1.2428 D(x): 0.9993 D(G(z)): 0.1059\n",
      "[31/100][2000/3165] Loss_D: 0.3097 Loss_G: 1.5803 D(x): 0.9367 D(G(z)): 0.5428\n",
      "[31/100][2500/3165] Loss_D: 0.0751 Loss_G: 1.3334 D(x): 0.7586 D(G(z)): 0.2133\n",
      "[31/100][3000/3165] Loss_D: 0.0210 Loss_G: 1.2719 D(x): 0.9971 D(G(z)): 0.0772\n",
      "[32/100][0/3165] Loss_D: 0.0713 Loss_G: 0.5688 D(x): 0.6978 D(G(z)): -0.1536\n",
      "[32/100][500/3165] Loss_D: 0.0524 Loss_G: 2.0248 D(x): 0.9208 D(G(z)): 0.2112\n",
      "[32/100][1000/3165] Loss_D: 0.0315 Loss_G: 1.2883 D(x): 0.9317 D(G(z)): 0.1547\n",
      "[32/100][1500/3165] Loss_D: 0.0026 Loss_G: 1.0041 D(x): 0.9200 D(G(z)): 0.0116\n",
      "[32/100][2000/3165] Loss_D: 0.0130 Loss_G: 0.9710 D(x): 0.9700 D(G(z)): -0.0576\n",
      "[32/100][2500/3165] Loss_D: 0.0126 Loss_G: 1.0814 D(x): 0.9741 D(G(z)): 0.0537\n",
      "[32/100][3000/3165] Loss_D: 0.0140 Loss_G: 0.9079 D(x): 0.8256 D(G(z)): -0.0497\n",
      "[33/100][0/3165] Loss_D: 0.0216 Loss_G: 0.5684 D(x): 0.7916 D(G(z)): -0.0648\n",
      "[33/100][500/3165] Loss_D: 0.0067 Loss_G: 1.0067 D(x): 0.8483 D(G(z)): 0.0308\n",
      "[33/100][1000/3165] Loss_D: 0.1056 Loss_G: 1.7388 D(x): 0.9855 D(G(z)): 0.2935\n",
      "[33/100][1500/3165] Loss_D: 0.0505 Loss_G: 0.9407 D(x): 1.0040 D(G(z)): -0.1631\n",
      "[33/100][2000/3165] Loss_D: 0.0504 Loss_G: 1.3227 D(x): 1.0358 D(G(z)): 0.1369\n",
      "[33/100][2500/3165] Loss_D: 0.0088 Loss_G: 0.9495 D(x): 0.8480 D(G(z)): -0.0186\n",
      "[33/100][3000/3165] Loss_D: 0.0119 Loss_G: 0.9311 D(x): 0.9062 D(G(z)): -0.0823\n",
      "[34/100][0/3165] Loss_D: 0.0202 Loss_G: 0.9339 D(x): 0.8232 D(G(z)): -0.0742\n",
      "[34/100][500/3165] Loss_D: 0.0086 Loss_G: 1.1401 D(x): 0.9554 D(G(z)): 0.0447\n",
      "[34/100][1000/3165] Loss_D: 0.0087 Loss_G: 0.9270 D(x): 0.8520 D(G(z)): -0.0042\n",
      "[34/100][1500/3165] Loss_D: 0.0434 Loss_G: 0.4948 D(x): 0.7963 D(G(z)): -0.1555\n",
      "[34/100][2000/3165] Loss_D: 0.0796 Loss_G: 1.6148 D(x): 0.9506 D(G(z)): 0.2624\n",
      "[34/100][2500/3165] Loss_D: 0.0267 Loss_G: 0.7266 D(x): 0.7809 D(G(z)): -0.0357\n",
      "[34/100][3000/3165] Loss_D: 0.0186 Loss_G: 0.8781 D(x): 0.8135 D(G(z)): -0.0019\n",
      "[35/100][0/3165] Loss_D: 0.0418 Loss_G: 0.6306 D(x): 0.7925 D(G(z)): -0.1295\n",
      "[35/100][500/3165] Loss_D: 0.1105 Loss_G: 1.4841 D(x): 0.8725 D(G(z)): 0.3138\n",
      "[35/100][1000/3165] Loss_D: 0.0304 Loss_G: 0.7130 D(x): 0.7755 D(G(z)): -0.0770\n",
      "[35/100][1500/3165] Loss_D: 0.0177 Loss_G: 0.9762 D(x): 0.8236 D(G(z)): 0.0402\n",
      "[35/100][2000/3165] Loss_D: 0.0582 Loss_G: 0.6021 D(x): 0.7014 D(G(z)): -0.1063\n",
      "[35/100][2500/3165] Loss_D: 0.0230 Loss_G: 0.8139 D(x): 0.8312 D(G(z)): -0.0899\n",
      "[35/100][3000/3165] Loss_D: 0.0127 Loss_G: 1.1200 D(x): 0.9448 D(G(z)): 0.0775\n",
      "[36/100][0/3165] Loss_D: 0.0456 Loss_G: 1.4831 D(x): 1.0527 D(G(z)): 0.1100\n",
      "[36/100][500/3165] Loss_D: 0.0167 Loss_G: 0.8305 D(x): 0.8176 D(G(z)): -0.0596\n",
      "[36/100][1000/3165] Loss_D: 0.0530 Loss_G: 0.4950 D(x): 0.7085 D(G(z)): -0.0874\n",
      "[36/100][1500/3165] Loss_D: 0.0207 Loss_G: 0.7227 D(x): 0.8615 D(G(z)): -0.1027\n",
      "[36/100][2000/3165] Loss_D: 0.0305 Loss_G: 0.7381 D(x): 0.7930 D(G(z)): -0.1064\n",
      "[36/100][2500/3165] Loss_D: 0.0553 Loss_G: 1.9200 D(x): 1.0043 D(G(z)): 0.2000\n",
      "[36/100][3000/3165] Loss_D: 0.0410 Loss_G: 1.3298 D(x): 1.0166 D(G(z)): 0.1382\n",
      "[37/100][0/3165] Loss_D: 0.0464 Loss_G: 1.4519 D(x): 1.0615 D(G(z)): 0.1137\n",
      "[37/100][500/3165] Loss_D: 0.0155 Loss_G: 1.1783 D(x): 0.9825 D(G(z)): 0.0345\n",
      "[37/100][1000/3165] Loss_D: 0.0147 Loss_G: 0.8850 D(x): 0.9383 D(G(z)): -0.0854\n",
      "[37/100][1500/3165] Loss_D: 0.0501 Loss_G: 0.8269 D(x): 0.6938 D(G(z)): 0.0458\n",
      "[37/100][2000/3165] Loss_D: 0.0465 Loss_G: 0.6661 D(x): 0.7111 D(G(z)): -0.0194\n",
      "[37/100][2500/3165] Loss_D: 0.0085 Loss_G: 1.0984 D(x): 0.9504 D(G(z)): 0.0449\n",
      "[37/100][3000/3165] Loss_D: 0.1998 Loss_G: 1.9204 D(x): 0.9902 D(G(z)): 0.4281\n",
      "[38/100][0/3165] Loss_D: 0.0042 Loss_G: 1.0023 D(x): 0.9087 D(G(z)): -0.0021\n",
      "[38/100][500/3165] Loss_D: 0.0045 Loss_G: 1.0118 D(x): 0.9306 D(G(z)): -0.0066\n",
      "[38/100][1000/3165] Loss_D: 0.0043 Loss_G: 0.9648 D(x): 0.9251 D(G(z)): -0.0243\n",
      "[38/100][1500/3165] Loss_D: 0.0432 Loss_G: 1.5282 D(x): 0.9662 D(G(z)): 0.1843\n",
      "[38/100][2000/3165] Loss_D: 0.0128 Loss_G: 1.0829 D(x): 0.9744 D(G(z)): 0.0616\n",
      "[38/100][2500/3165] Loss_D: 0.0298 Loss_G: 0.8607 D(x): 0.7559 D(G(z)): 0.0219\n",
      "[38/100][3000/3165] Loss_D: 0.1493 Loss_G: 1.7262 D(x): 1.0970 D(G(z)): 0.3131\n",
      "[39/100][0/3165] Loss_D: 0.0210 Loss_G: 0.7148 D(x): 0.8279 D(G(z)): -0.0836\n",
      "[39/100][500/3165] Loss_D: 0.0094 Loss_G: 1.0384 D(x): 0.9298 D(G(z)): -0.0061\n",
      "[39/100][1000/3165] Loss_D: 0.0137 Loss_G: 1.0734 D(x): 0.9745 D(G(z)): 0.0327\n",
      "[39/100][1500/3165] Loss_D: 0.0048 Loss_G: 0.9808 D(x): 0.8864 D(G(z)): -0.0103\n",
      "[39/100][2000/3165] Loss_D: 0.0105 Loss_G: 1.0903 D(x): 0.9437 D(G(z)): 0.0611\n",
      "[39/100][2500/3165] Loss_D: 0.0092 Loss_G: 1.1011 D(x): 0.9601 D(G(z)): 0.0265\n",
      "[39/100][3000/3165] Loss_D: 0.0077 Loss_G: 0.9925 D(x): 0.8547 D(G(z)): 0.0427\n",
      "[40/100][0/3165] Loss_D: 0.0093 Loss_G: 1.0331 D(x): 0.9077 D(G(z)): 0.0764\n",
      "[40/100][500/3165] Loss_D: 0.0048 Loss_G: 1.0189 D(x): 0.8765 D(G(z)): 0.0279\n",
      "[40/100][1000/3165] Loss_D: 0.0036 Loss_G: 1.0355 D(x): 0.9224 D(G(z)): 0.0235\n",
      "[40/100][1500/3165] Loss_D: 0.0337 Loss_G: 0.7065 D(x): 0.7987 D(G(z)): -0.1309\n",
      "[40/100][2000/3165] Loss_D: 0.0353 Loss_G: 1.1702 D(x): 0.8361 D(G(z)): 0.1507\n",
      "[40/100][2500/3165] Loss_D: 0.0201 Loss_G: 0.6278 D(x): 0.7905 D(G(z)): -0.0530\n",
      "[40/100][3000/3165] Loss_D: 0.0108 Loss_G: 1.0896 D(x): 0.9721 D(G(z)): 0.0108\n",
      "[41/100][0/3165] Loss_D: 0.0175 Loss_G: 0.8849 D(x): 0.8228 D(G(z)): -0.0880\n",
      "[41/100][500/3165] Loss_D: 0.0599 Loss_G: 0.8581 D(x): 0.6926 D(G(z)): 0.0937\n",
      "[41/100][1000/3165] Loss_D: 0.0166 Loss_G: 0.8559 D(x): 0.7982 D(G(z)): 0.0089\n",
      "[41/100][1500/3165] Loss_D: 0.0038 Loss_G: 0.9946 D(x): 0.9278 D(G(z)): -0.0099\n",
      "[41/100][2000/3165] Loss_D: 0.0260 Loss_G: 1.0442 D(x): 1.0248 D(G(z)): 0.0447\n",
      "[41/100][2500/3165] Loss_D: 0.0147 Loss_G: 0.8024 D(x): 0.8768 D(G(z)): -0.0746\n",
      "[41/100][3000/3165] Loss_D: 0.0164 Loss_G: 1.2709 D(x): 0.9114 D(G(z)): 0.0992\n",
      "[42/100][0/3165] Loss_D: 0.0055 Loss_G: 0.9994 D(x): 0.9048 D(G(z)): -0.0281\n",
      "[42/100][500/3165] Loss_D: 0.0098 Loss_G: 1.1843 D(x): 0.9173 D(G(z)): 0.0758\n",
      "[42/100][1000/3165] Loss_D: 0.4391 Loss_G: 1.5013 D(x): 0.9855 D(G(z)): 0.6511\n",
      "[42/100][1500/3165] Loss_D: 0.0032 Loss_G: 0.9999 D(x): 0.9264 D(G(z)): -0.0075\n",
      "[42/100][2000/3165] Loss_D: 0.0038 Loss_G: 0.9999 D(x): 0.9287 D(G(z)): -0.0000\n",
      "[42/100][2500/3165] Loss_D: 0.0081 Loss_G: 1.0329 D(x): 0.9360 D(G(z)): -0.0025\n",
      "[42/100][3000/3165] Loss_D: 0.0063 Loss_G: 0.9988 D(x): 0.8881 D(G(z)): -0.0221\n",
      "[43/100][0/3165] Loss_D: 0.0128 Loss_G: 1.0374 D(x): 0.8527 D(G(z)): 0.0675\n",
      "[43/100][500/3165] Loss_D: 0.0085 Loss_G: 0.9667 D(x): 0.8224 D(G(z)): -0.0076\n",
      "[43/100][1000/3165] Loss_D: 0.0602 Loss_G: 1.4694 D(x): 0.9447 D(G(z)): 0.2215\n",
      "[43/100][1500/3165] Loss_D: 0.0111 Loss_G: 1.0053 D(x): 0.8744 D(G(z)): 0.0160\n",
      "[43/100][2000/3165] Loss_D: 0.0498 Loss_G: 1.4963 D(x): 0.9674 D(G(z)): 0.1939\n",
      "[43/100][2500/3165] Loss_D: 0.0140 Loss_G: 1.1135 D(x): 0.9727 D(G(z)): 0.0443\n",
      "[43/100][3000/3165] Loss_D: 0.0761 Loss_G: 0.7475 D(x): 0.6467 D(G(z)): 0.0795\n",
      "[44/100][0/3165] Loss_D: 0.0051 Loss_G: 0.9522 D(x): 0.8701 D(G(z)): -0.0426\n",
      "[44/100][500/3165] Loss_D: 0.0130 Loss_G: 0.9464 D(x): 0.8205 D(G(z)): -0.0271\n",
      "[44/100][1000/3165] Loss_D: 0.0076 Loss_G: 0.9732 D(x): 0.8422 D(G(z)): 0.0026\n",
      "[44/100][1500/3165] Loss_D: 0.0519 Loss_G: 0.5603 D(x): 0.6892 D(G(z)): 0.0491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44/100][2000/3165] Loss_D: 0.0230 Loss_G: 1.0895 D(x): 0.8362 D(G(z)): 0.1122\n",
      "[44/100][2500/3165] Loss_D: 0.0193 Loss_G: 0.9585 D(x): 0.8815 D(G(z)): -0.1262\n",
      "[44/100][3000/3165] Loss_D: 0.0230 Loss_G: 0.6128 D(x): 0.8058 D(G(z)): -0.0857\n",
      "[45/100][0/3165] Loss_D: 0.0054 Loss_G: 0.9970 D(x): 0.8904 D(G(z)): -0.0115\n",
      "[45/100][500/3165] Loss_D: 0.0143 Loss_G: 1.3226 D(x): 0.8938 D(G(z)): 0.1008\n",
      "[45/100][1000/3165] Loss_D: 0.0044 Loss_G: 1.0008 D(x): 0.8995 D(G(z)): -0.0274\n",
      "[45/100][1500/3165] Loss_D: 0.0234 Loss_G: 1.2306 D(x): 0.9510 D(G(z)): 0.1203\n",
      "[45/100][2000/3165] Loss_D: 0.0097 Loss_G: 0.9804 D(x): 0.8190 D(G(z)): -0.0032\n",
      "[45/100][2500/3165] Loss_D: 0.1407 Loss_G: 0.5459 D(x): 0.5544 D(G(z)): -0.1080\n",
      "[45/100][3000/3165] Loss_D: 0.0035 Loss_G: 1.0552 D(x): 0.9381 D(G(z)): 0.0231\n",
      "[46/100][0/3165] Loss_D: 0.0042 Loss_G: 1.0829 D(x): 0.8848 D(G(z)): 0.0446\n",
      "[46/100][500/3165] Loss_D: 0.0186 Loss_G: 0.7963 D(x): 0.8416 D(G(z)): -0.1099\n",
      "[46/100][1000/3165] Loss_D: 0.0296 Loss_G: 0.8111 D(x): 0.7565 D(G(z)): -0.0296\n",
      "[46/100][1500/3165] Loss_D: 0.0675 Loss_G: 0.6792 D(x): 0.6574 D(G(z)): 0.0118\n",
      "[46/100][2000/3165] Loss_D: 0.0521 Loss_G: 0.6105 D(x): 0.7388 D(G(z)): -0.1279\n",
      "[46/100][2500/3165] Loss_D: 0.0235 Loss_G: 1.3331 D(x): 0.9031 D(G(z)): 0.1280\n",
      "[46/100][3000/3165] Loss_D: 0.0142 Loss_G: 1.1788 D(x): 0.9276 D(G(z)): 0.0689\n",
      "[47/100][0/3165] Loss_D: 0.0374 Loss_G: 0.7670 D(x): 0.7302 D(G(z)): -0.0229\n",
      "[47/100][500/3165] Loss_D: 0.0162 Loss_G: 1.2068 D(x): 0.9745 D(G(z)): 0.0382\n",
      "[47/100][1000/3165] Loss_D: 0.0164 Loss_G: 0.9282 D(x): 0.8015 D(G(z)): 0.0339\n",
      "[47/100][1500/3165] Loss_D: 0.1482 Loss_G: 1.7995 D(x): 0.9125 D(G(z)): 0.3728\n",
      "[47/100][2000/3165] Loss_D: 0.0843 Loss_G: 1.6346 D(x): 0.9741 D(G(z)): 0.2533\n",
      "[47/100][2500/3165] Loss_D: 0.0335 Loss_G: 1.2819 D(x): 0.8567 D(G(z)): 0.1348\n",
      "[47/100][3000/3165] Loss_D: 0.0120 Loss_G: 0.8583 D(x): 0.8385 D(G(z)): -0.0195\n",
      "[48/100][0/3165] Loss_D: 0.1560 Loss_G: 1.9455 D(x): 1.0928 D(G(z)): 0.3303\n",
      "[48/100][500/3165] Loss_D: 0.0618 Loss_G: 1.4261 D(x): 0.9961 D(G(z)): 0.2127\n",
      "[48/100][1000/3165] Loss_D: 0.0248 Loss_G: 0.9332 D(x): 0.7790 D(G(z)): 0.0431\n",
      "[48/100][1500/3165] Loss_D: 0.0352 Loss_G: 1.1743 D(x): 0.8256 D(G(z)): 0.1368\n",
      "[48/100][2000/3165] Loss_D: 0.0128 Loss_G: 1.1933 D(x): 0.9371 D(G(z)): 0.0592\n",
      "[48/100][2500/3165] Loss_D: 0.0080 Loss_G: 0.9487 D(x): 0.8519 D(G(z)): 0.0260\n",
      "[48/100][3000/3165] Loss_D: 0.0379 Loss_G: 1.4417 D(x): 0.8955 D(G(z)): 0.1756\n",
      "[49/100][0/3165] Loss_D: 0.0450 Loss_G: 1.1929 D(x): 0.8553 D(G(z)): 0.1839\n",
      "[49/100][500/3165] Loss_D: 0.0096 Loss_G: 0.9443 D(x): 0.8531 D(G(z)): -0.0094\n",
      "[49/100][1000/3165] Loss_D: 0.0117 Loss_G: 1.0316 D(x): 0.8484 D(G(z)): 0.0498\n",
      "[49/100][1500/3165] Loss_D: 0.0095 Loss_G: 0.9406 D(x): 0.8340 D(G(z)): -0.0169\n",
      "[49/100][2000/3165] Loss_D: 0.0061 Loss_G: 1.1019 D(x): 0.9253 D(G(z)): 0.0545\n",
      "[49/100][2500/3165] Loss_D: 0.0024 Loss_G: 1.0117 D(x): 0.8940 D(G(z)): 0.0088\n",
      "[49/100][3000/3165] Loss_D: 0.0429 Loss_G: 1.2457 D(x): 0.8613 D(G(z)): 0.1838\n",
      "[50/100][0/3165] Loss_D: 0.1835 Loss_G: 1.5142 D(x): 1.0133 D(G(z)): 0.4027\n",
      "[50/100][500/3165] Loss_D: 0.0721 Loss_G: 1.4284 D(x): 0.8522 D(G(z)): 0.2489\n",
      "[50/100][1000/3165] Loss_D: 0.0198 Loss_G: 0.6578 D(x): 0.8448 D(G(z)): -0.0999\n",
      "[50/100][1500/3165] Loss_D: 0.0296 Loss_G: 1.2361 D(x): 0.8719 D(G(z)): 0.1473\n",
      "[50/100][2000/3165] Loss_D: 0.0321 Loss_G: 0.7422 D(x): 0.7464 D(G(z)): 0.0020\n",
      "[50/100][2500/3165] Loss_D: 0.0203 Loss_G: 0.9109 D(x): 0.9820 D(G(z)): -0.0795\n",
      "[50/100][3000/3165] Loss_D: 0.0208 Loss_G: 1.1474 D(x): 0.8349 D(G(z)): 0.0923\n",
      "[51/100][0/3165] Loss_D: 0.2022 Loss_G: 2.1282 D(x): 1.1261 D(G(z)): 0.3800\n",
      "[51/100][500/3165] Loss_D: 0.0103 Loss_G: 1.0779 D(x): 0.8813 D(G(z)): 0.0291\n",
      "[51/100][1000/3165] Loss_D: 0.0336 Loss_G: 1.2723 D(x): 0.8997 D(G(z)): 0.1362\n",
      "[51/100][1500/3165] Loss_D: 0.0160 Loss_G: 0.9580 D(x): 0.8269 D(G(z)): 0.0383\n",
      "[51/100][2000/3165] Loss_D: 0.0611 Loss_G: 1.3268 D(x): 0.8844 D(G(z)): 0.2221\n",
      "[51/100][2500/3165] Loss_D: 0.0147 Loss_G: 0.9491 D(x): 0.8307 D(G(z)): 0.0122\n",
      "[51/100][3000/3165] Loss_D: 0.0623 Loss_G: 0.5983 D(x): 0.7610 D(G(z)): -0.1870\n",
      "[52/100][0/3165] Loss_D: 0.0275 Loss_G: 1.3369 D(x): 0.9108 D(G(z)): 0.1368\n",
      "[52/100][500/3165] Loss_D: 0.1154 Loss_G: 0.5694 D(x): 0.6390 D(G(z)): -0.1955\n",
      "[52/100][1000/3165] Loss_D: 0.3192 Loss_G: 2.0449 D(x): 1.0772 D(G(z)): 0.5268\n",
      "[52/100][1500/3165] Loss_D: 0.0380 Loss_G: 0.9114 D(x): 0.7428 D(G(z)): 0.0475\n",
      "[52/100][2000/3165] Loss_D: 0.1199 Loss_G: 0.4445 D(x): 0.5834 D(G(z)): -0.0923\n",
      "[52/100][2500/3165] Loss_D: 0.0322 Loss_G: 1.3589 D(x): 0.9277 D(G(z)): 0.1454\n",
      "[52/100][3000/3165] Loss_D: 0.0218 Loss_G: 0.8170 D(x): 0.7938 D(G(z)): -0.0067\n",
      "[53/100][0/3165] Loss_D: 0.0252 Loss_G: 1.1056 D(x): 0.8048 D(G(z)): 0.0836\n",
      "[53/100][500/3165] Loss_D: 0.0590 Loss_G: 1.4728 D(x): 0.9449 D(G(z)): 0.2155\n",
      "[53/100][1000/3165] Loss_D: 0.0304 Loss_G: 0.7385 D(x): 0.8263 D(G(z)): -0.1274\n",
      "[53/100][1500/3165] Loss_D: 0.0222 Loss_G: 0.8229 D(x): 0.7902 D(G(z)): -0.0127\n",
      "[53/100][2000/3165] Loss_D: 0.0155 Loss_G: 0.8394 D(x): 0.8220 D(G(z)): -0.0048\n",
      "[53/100][2500/3165] Loss_D: 0.0404 Loss_G: 0.6036 D(x): 0.7299 D(G(z)): -0.0582\n",
      "[53/100][3000/3165] Loss_D: 0.0447 Loss_G: 1.3613 D(x): 0.8949 D(G(z)): 0.1793\n",
      "[54/100][0/3165] Loss_D: 0.0680 Loss_G: 0.8395 D(x): 0.6786 D(G(z)): 0.0610\n",
      "[54/100][500/3165] Loss_D: 0.0641 Loss_G: 0.4611 D(x): 0.6682 D(G(z)): -0.0423\n",
      "[54/100][1000/3165] Loss_D: 0.0176 Loss_G: 1.0791 D(x): 0.8844 D(G(z)): 0.1011\n",
      "[54/100][1500/3165] Loss_D: 0.0552 Loss_G: 1.4273 D(x): 1.0319 D(G(z)): 0.1741\n",
      "[54/100][2000/3165] Loss_D: 0.0105 Loss_G: 1.1478 D(x): 0.8941 D(G(z)): 0.0690\n",
      "[54/100][2500/3165] Loss_D: 0.0183 Loss_G: 1.2935 D(x): 0.9736 D(G(z)): 0.0770\n",
      "[54/100][3000/3165] Loss_D: 0.0455 Loss_G: 1.2733 D(x): 0.8597 D(G(z)): 0.1758\n",
      "[55/100][0/3165] Loss_D: 0.0919 Loss_G: 0.3370 D(x): 0.8767 D(G(z)): -0.2808\n",
      "[55/100][500/3165] Loss_D: 0.0446 Loss_G: 0.7004 D(x): 0.7155 D(G(z)): 0.0257\n",
      "[55/100][1000/3165] Loss_D: 0.0289 Loss_G: 0.7026 D(x): 0.7898 D(G(z)): -0.0878\n",
      "[55/100][1500/3165] Loss_D: 0.0262 Loss_G: 0.9997 D(x): 0.8098 D(G(z)): 0.0875\n",
      "[55/100][2000/3165] Loss_D: 0.0233 Loss_G: 1.1950 D(x): 0.9925 D(G(z)): 0.0857\n",
      "[55/100][2500/3165] Loss_D: 0.0769 Loss_G: 0.4658 D(x): 0.6920 D(G(z)): -0.1556\n",
      "[55/100][3000/3165] Loss_D: 0.0158 Loss_G: 0.8759 D(x): 0.8160 D(G(z)): -0.0294\n",
      "[56/100][0/3165] Loss_D: 0.0110 Loss_G: 0.9383 D(x): 0.9325 D(G(z)): -0.0462\n"
     ]
    }
   ],
   "source": [
    "niter = 100\n",
    "d_fake_save = None\n",
    "for epoch in range(niter):\n",
    "#     if epoch < 4:\n",
    "#         continue\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # train D\n",
    "        netD.zero_grad()\n",
    "        real_cpu, feature_input_cpu = data\n",
    "        batch_size = real_cpu.size(0)\n",
    "\n",
    "        real = real_cpu.cuda()        \n",
    "        inputv = Variable(real)\n",
    "        \n",
    "        feature_input = feature_input_cpu.cuda()\n",
    "        feature_inputv = Variable(feature_input)\n",
    "        feature = feature_net(feature_inputv)\n",
    "        feature_noise = (1 - torch.FloatTensor(batch_size, 512).normal_(0, 0.05)).cuda()\n",
    "        feature *= feature_noise\n",
    "        \n",
    "        d_real = netD(add_noise(inputv, d_fake_save), feature.detach())\n",
    "        d_real_mean = d_real.data.mean()\n",
    "        \n",
    "        noise.resize_(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "        noisev = Variable(noise)\n",
    "        fake = netG(noisev, feature.detach())\n",
    "        \n",
    "        d_fake_save = d_fake = netD(add_noise(fake.detach(), d_fake_save), feature.detach())\n",
    "        d_fake_mean = d_fake.data.mean()\n",
    "        \n",
    "        loss_d = criterion(d_real, label_real_smooth) + criterion(d_fake, label_fake)\n",
    "        loss_d.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # train G\n",
    "        netG.zero_grad()\n",
    "        d_fake = netD(fake, feature.detach())\n",
    "        loss_g = criterion(d_fake, label_real.detach())\n",
    "        loss_g.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i%500 == 0:\n",
    "            fake = netG(fixed_noise, feature.detach())\n",
    "            vutils.save_image(fake.data,\n",
    "                    '%s/fake_samples_epoch_%03dstep_%04d.png' % (outf, epoch, i),\n",
    "                    normalize=True)\n",
    "#             vutils.save_image(inputv.data,\n",
    "#                     '%s/fake_samples_epoch_%03dstep_%04d_input.png' % (outf, epoch, i),\n",
    "#                     normalize=True)\n",
    "            vutils.save_image(feature_inputv.data,\n",
    "                    '%s/fake_samples_epoch_%03dstep_%04d_feature.png' % (outf, epoch, i),\n",
    "                    normalize=True)\n",
    "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f'\n",
    "                  % (epoch, niter, i, len(dataloader),\n",
    "                     loss_d.data[0], loss_g.data[0], d_real_mean, d_fake_mean))\n",
    "            \n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%03d.pth' % (outf, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%03d.pth' % (outf, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
